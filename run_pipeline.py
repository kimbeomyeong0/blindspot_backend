#!/usr/bin/env python3
"""
BlindSpot ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì‹¤í–‰ ìˆœì„œ:
1. ğŸ“° ê¸°ì‚¬ í¬ë¡¤ë§ (ë³‘ë ¬ ì²˜ë¦¬)
2. ğŸ§  ê¸°ì‚¬ ë¶„ì„ (ì„ë² ë”© â†’ í´ëŸ¬ìŠ¤í„°ë§ â†’ ìš”ì•½)
3. ğŸ“Š ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
"""

import os
import sys
import time
from datetime import datetime
import openai
from dotenv import load_dotenv
from collections import Counter, defaultdict

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ëª¨ë“ˆ import
from main_crawler import crawl_all_parallel
from supabase_utils import init_supabase, load_articles_from_db, save_cluster_to_db, save_cluster_articles_to_db, save_analysis_session_to_db
from analyzer import cluster_articles, analyze_cluster_topics, analyze_media_bias, generate_report
from report_utils import save_markdown_report

class BlindSpotPipeline:
    def __init__(self, openai_api_key):
        """íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        self.supabase = init_supabase()
        print("ğŸ¤– BlindSpot íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def calculate_optimal_clusters(self, article_count):
        """ê¸°ì‚¬ ìˆ˜ì— ë”°ë¼ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê³„ì‚° (ìµœëŒ€ 15ê°œ ì œí•œ)"""
        if article_count < 30:
            return 3
        elif article_count < 60:
            return 5
        elif article_count < 120:
            return 8
        elif article_count < 200:
            return 10
        else:
            return min(15, max(8, article_count // 25))  # ê¸°ì‚¬ 25ê°œë‹¹ 1ê°œ í´ëŸ¬ìŠ¤í„°, ìµœëŒ€ 15ê°œ ì œí•œ
        
    def step1_crawl_articles(self):
        """1ë‹¨ê³„: ê¸°ì‚¬ í¬ë¡¤ë§"""
        print("\n" + "="*60)
        print("ğŸ“° 1ë‹¨ê³„: ê¸°ì‚¬ í¬ë¡¤ë§ ì‹œì‘")
        print("="*60)
        
        start_time = time.time()
        articles = crawl_all_parallel()
        end_time = time.time()
        
        print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì†Œìš”ì‹œê°„: {end_time - start_time:.1f}ì´ˆ")
        print(f"ğŸ“Š ìˆ˜ì§‘ëœ ê¸°ì‚¬: {len(articles)}ê°œ")
        
        return articles
    
    def step2_analyze_articles(self, n_clusters=None):
        """2ë‹¨ê³„: ê¸°ì‚¬ ë¶„ì„ (ì¹´í…Œê³ ë¦¬ë³„ í´ëŸ¬ìŠ¤í„°ë§)"""
        print("\n" + "="*60)
        print("ğŸ§  2ë‹¨ê³„: ê¸°ì‚¬ ë¶„ì„ ì‹œì‘ (ì¹´í…Œê³ ë¦¬ë³„)")
        print("="*60)
        
        # DBì—ì„œ ê¸°ì‚¬ ë¡œë“œ
        print("ğŸ“Š DBì—ì„œ ê¸°ì‚¬ ë°ì´í„° ë¡œë“œ ì¤‘...")
        articles = load_articles_from_db(self.supabase)
        
        if not articles:
            print("âŒ ë¶„ì„í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ“Š ì´ {len(articles)}ê°œ ê¸°ì‚¬ ë¡œë“œ ì™„ë£Œ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê¸°ì‚¬ ë¶„ë¦¬
        articles_by_category = {}
        for article in articles:
            category = None
            if 'categories' in article and isinstance(article['categories'], dict):
                category = article['categories'].get('name')
            elif 'category' in article:
                category = article['category']
            if category:
                articles_by_category.setdefault(category, []).append(article)

        all_results = []
        report_clusters = []
        all_article_ids = set()
        for category, articles_in_cat in articles_by_category.items():
            if not articles_in_cat:
                continue
            print(f"\n[{category}] ê¸°ì‚¬ {len(articles_in_cat)}ê°œ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘!")
            n_cat_clusters = self.calculate_optimal_clusters(len(articles_in_cat)) if n_clusters is None else n_clusters
            print(f"[DEBUG] {category} n_clusters: {n_cat_clusters}")
            result = cluster_articles(self.openai_client, articles_in_cat, n_cat_clusters)
            if result is None:
                print(f"{category} í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨")
                continue
            clustered_articles, cluster_centers = result
            print(f"[DEBUG] {category} í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: {n_cat_clusters}, ì‹¤ì œ í´ëŸ¬ìŠ¤í„°ë§ëœ ê¸°ì‚¬ ìˆ˜: {len(clustered_articles)}")
            cluster_topics = analyze_cluster_topics(self.openai_client, clustered_articles)
            bias_analysis = analyze_media_bias(cluster_topics)
            report = generate_report(bias_analysis)
            all_results.append({
                'category': category,
                'clustered_articles': clustered_articles,
                'cluster_topics': cluster_topics,
                'bias_analysis': bias_analysis,
                'report': report
            })
            self.save_analysis_results_to_db(clustered_articles, cluster_topics, bias_analysis, category)
            # ë¦¬í¬íŠ¸ìš© ë°ì´í„° ëˆ„ì  (run_cluster_save.pyì™€ ë™ì¼í•˜ê²Œ)
            for cluster_id, articles_in_cluster in enumerate(clustered_articles):
                cluster_info = cluster_topics.get(cluster_id, {})
                if not cluster_info.get('summary'):
                    continue
                # ì–¸ë¡ ì‚¬/í¸í–¥ ì§‘ê³„
                media_counter = Counter()
                bias_counter = Counter()
                media_bias_map = defaultdict(str)
                for a in articles_in_cluster:
                    media = None
                    bias = None
                    if 'media_outlets' in a and isinstance(a['media_outlets'], dict):
                        media = a['media_outlets'].get('name')
                        bias = a['media_outlets'].get('bias')
                    if not media and 'media' in a:
                        media = a['media']
                    if not bias and 'bias' in a:
                        bias = a['bias']
                    if media:
                        media_counter[media] += 1
                        if bias:
                            media_bias_map[media] = bias
                    if bias:
                        bias_counter[bias] += 1
                total = sum(bias_counter.values())
                bias_pct = {k: (v, v/total*100 if total else 0) for k, v in bias_counter.items()}
                bias_judgement = 'âš–ï¸ ê· í˜•ì  ë³´ë„'
                if len(bias_counter) == 1:
                    if 'left' in bias_counter:
                        bias_judgement = 'ğŸ”´ ì¢Œí¸í–¥ ìš°ì„¸'
                    elif 'right' in bias_counter:
                        bias_judgement = 'ğŸ”µ ìš°í¸í–¥ ìš°ì„¸'
                    elif 'center' in bias_counter:
                        bias_judgement = 'âšª ì¤‘ë¦½ ìš°ì„¸'
                elif bias_counter:
                    max_bias, max_count = bias_counter.most_common(1)[0]
                    max_pct = bias_pct[max_bias][1]
                    if max_pct >= 55:
                        if max_bias == 'left':
                            bias_judgement = 'ğŸ”´ ì¢Œí¸í–¥ ìš°ì„¸'
                        elif max_bias == 'right':
                            bias_judgement = 'ğŸ”µ ìš°í¸í–¥ ìš°ì„¸'
                        elif max_bias == 'center':
                            bias_judgement = 'âšª ì¤‘ë¦½ ìš°ì„¸'
                topic = cluster_info.get('topic_analysis', f'í´ëŸ¬ìŠ¤í„° {cluster_id}')
                summary = cluster_info.get('summary', '')
                keywords = cluster_info.get('keywords', None)
                field = cluster_info.get('ë¶„ì•¼', None) or cluster_info.get('field', None) or category
                if isinstance(articles_in_cluster, dict):
                    article_ids = [articles_in_cluster.get('id')] if articles_in_cluster.get('id') else []
                elif isinstance(articles_in_cluster, list) and articles_in_cluster and isinstance(articles_in_cluster[0], dict):
                    article_ids = [a.get('id') for a in articles_in_cluster if a.get('id')]
                elif isinstance(articles_in_cluster, list):
                    article_ids = [a for a in articles_in_cluster if a]
                else:
                    article_ids = []
                all_article_ids.update(article_ids)
                report_clusters.append({
                    'cluster_id': cluster_id,
                    'topic': topic,
                    'summary': summary,
                    'keywords': keywords,
                    'field': field,
                    'category': category,
                    'article_count': len(articles_in_cluster),
                    'media_counter': dict(media_counter),
                    'media_bias_map': dict(media_bias_map),
                    'bias_counter': dict(bias_counter),
                    'bias_pct': bias_pct,
                    'bias_judgement': bias_judgement,
                    'article_ids': article_ids
                })
        if report_clusters:
            save_markdown_report(report_clusters, all_article_ids)
        return all_results
    
    def save_analysis_results_to_db(self, clustered_articles, cluster_topics, bias_analysis, category=None):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì¹´í…Œê³ ë¦¬ í¬í•¨)"""
        try:
            print("ğŸ“Š í´ëŸ¬ìŠ¤í„° ì •ë³´ ì €ì¥ ì¤‘...")
            # í´ëŸ¬ìŠ¤í„°ë³„ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            clusters_dict = {}
            for article in clustered_articles:
                cid = article['cluster_id']
                if cid not in clusters_dict:
                    clusters_dict[cid] = []
                clusters_dict[cid].append(article)
            for cluster_id, articles_in_cluster in clusters_dict.items():
                cluster_info = cluster_topics.get(cluster_id, {})
                # summaryë§Œ ì²´í¬
                if not cluster_info.get('summary'):
                    print(f"âŒ íŒŒì‹± ì‹¤íŒ¨: cluster_id={cluster_id}, summary='{cluster_info.get('summary')}'")
                    continue
                cluster_data = {
                    'cluster_id': cluster_id,
                    'category': category,
                    'topic': cluster_info.get('topic', f'í´ëŸ¬ìŠ¤í„° {cluster_id}'),
                    'summary': cluster_info.get('summary', ''),
                    'article_count': len(articles_in_cluster)
                }
                print("ì €ì¥ ì‹œë„:", cluster_data)
                print(f"í´ëŸ¬ìŠ¤í„° {cluster_id} ì˜ˆì‹œ:", articles_in_cluster[:1])
                print("íƒ€ì…:", type(articles_in_cluster))
                save_cluster_to_db(self.supabase, cluster_data)

                # ê¸°ì‚¬ ID ì €ì¥
                article_ids = [a.get('id') for a in articles_in_cluster if a.get('id')]
                if article_ids:
                    save_cluster_articles_to_db(self.supabase, cluster_id, article_ids)
            print(f"âœ… [{category}] í´ëŸ¬ìŠ¤í„° DB ì €ì¥ ì™„ë£Œ!")
            return True
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def save_report(self, report):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥"""
        # reports í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        reports_dir = "reports"
        if not os.path.exists(reports_dir):
            os.makedirs(reports_dir)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = os.path.join(reports_dir, f"blindspot_analysis_{timestamp}.md")
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_filename}")
        return report_filename
    
    def run_full_pipeline(self, n_clusters=None):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ BlindSpot ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
        print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        total_start_time = time.time()
        
        try:
            # 1ë‹¨ê³„: í¬ë¡¤ë§
            articles = self.step1_crawl_articles()
            
            # 2ë‹¨ê³„: ë¶„ì„
            analysis_results = self.step2_analyze_articles(n_clusters)
            
            if analysis_results:
                # ë¦¬í¬íŠ¸ ì €ì¥
                report_filename = self.save_report(analysis_results[0]['report'])
                
                total_end_time = time.time()
                total_duration = total_end_time - total_start_time
                
                print("\n" + "="*60)
                print("ğŸ‰ BlindSpot íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                print("="*60)
                print(f"â° ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_duration:.1f}ì´ˆ")
                print(f"ğŸ“Š ìˆ˜ì§‘ëœ ê¸°ì‚¬: {len(articles)}ê°œ")
                print(f"ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸: {report_filename}")
                
                # ë¦¬í¬íŠ¸ ë‚´ìš© ì¶œë ¥
                print("\n" + "="*60)
                print("ğŸ“‹ ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
                print("="*60)
                print(analysis_results[0]['report'][:1000] + "...")
                
                return {
                    'success': True,
                    'articles_count': len(articles),
                    'report_filename': report_filename,
                    'total_duration': total_duration
                }
            else:
                print("âŒ ë¶„ì„ ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return {'success': False, 'error': 'ë¶„ì„ ì‹¤íŒ¨'}
                
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”‘ BlindSpot íŒŒì´í”„ë¼ì¸")
    print("="*40)
    
    # OpenAI API í‚¤ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return
    
    # í´ëŸ¬ìŠ¤í„° ìˆ˜ëŠ” ë¬´ì¡°ê±´ ìë™ ê³„ì‚°
    n_clusters = None
    
    # OpenAI ëª¨ë¸ëª…ì€ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    openai_model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = BlindSpotPipeline(api_key)
    result = pipeline.run_full_pipeline(n_clusters)
    
    if result['success']:
        print(f"\nğŸ‰ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“Š ìˆ˜ì§‘ëœ ê¸°ì‚¬: {result['articles_count']}ê°œ")
        print(f"ğŸ“‹ ë¦¬í¬íŠ¸ íŒŒì¼: {result['report_filename']}")
        print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {result['total_duration']:.1f}ì´ˆ")
    else:
        print(f"\nâŒ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

if __name__ == "__main__":
    main() 