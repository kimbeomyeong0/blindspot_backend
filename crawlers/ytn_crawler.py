from playwright.sync_api import sync_playwright
import time
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ supabase_clientë¥¼ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from supabase_client import save_article_to_db, init_supabase

def crawl_ytn():
    # Supabase ì´ˆê¸°í™”
    supabase = init_supabase()
    print("ğŸ”— Supabase ì—°ê²° ì™„ë£Œ")
    
    # YTN ì¹´í…Œê³ ë¦¬ë³„ URL
    categories = [
        {"name": "ì •ì¹˜", "url": "https://www.ytn.co.kr/news/list.php?mcd=0101"},
        {"name": "ê²½ì œ", "url": "https://www.ytn.co.kr/news/list.php?mcd=0102"},
        {"name": "ì‚¬íšŒ", "url": "https://www.ytn.co.kr/news/list.php?mcd=0103"},
    ]
    
    with sync_playwright() as p:
        # ë¸Œë¼ìš°ì € ìµœì í™” ì˜µì…˜ ì ìš©
        browser = p.chromium.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage', 
                '--disable-images',
                '--disable-plugins',
                '--disable-extensions',
                '--no-first-run',
                '--disable-default-apps'
            ]
        )
        page = browser.new_page()
        all_articles = []

        for category in categories:
            print(f"\n=== YTN {category['name']} ê¸°ì‚¬ í¬ë¡¤ë§ ì‹œì‘ ===")
            page.goto(category['url'])
            time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            # ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ì„œ ë” ë§ì€ ê¸°ì‚¬ ë¡œë“œ
            for i in range(5):  # 5ë²ˆ ìŠ¤í¬ë¡¤
                page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                time.sleep(1)
                
                # ë”ë³´ê¸° ë²„íŠ¼ì´ ìˆë‹¤ë©´ í´ë¦­
                try:
                    more_button = page.query_selector("button:has-text('ë”ë³´ê¸°'), .more-btn, .btn-more, .more")
                    if more_button and more_button.is_visible():
                        more_button.click()
                        time.sleep(2)
                        print(f"ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ {i+1}/5")
                except:
                    pass
            
            # YTN ê¸°ì‚¬ ë§í¬ ìˆ˜ì§‘ (ì˜¬ë°”ë¥¸ ì…€ë ‰í„° ì‚¬ìš©)
            article_links = page.query_selector_all("a[href*='/news/']")
            print(f"ë°œê²¬ëœ ê¸°ì‚¬ ë§í¬: {len(article_links)}ê°œ")
            
            article_urls = []
            for link in article_links[:30]:  # ìƒìœ„ 30ê°œë§Œ
                try:
                    href = link.get_attribute("href")
                    if href:
                        # YTN ë§í¬ëŠ” ì´ë¯¸ ì ˆëŒ€ URL
                        if href.startswith("https://www.ytn.co.kr"):
                            article_urls.append(href)
                        elif href.startswith("/"):
                            article_urls.append("https://www.ytn.co.kr" + href)
                except:
                    continue
            
            print(f"ìˆ˜ì§‘ëœ ê¸°ì‚¬ URL: {len(article_urls)}ê°œ")
            
            # ê° ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ ë³¸ë¬¸ ì¶”ì¶œ
            article_count = 0
            for i, article_url in enumerate(article_urls):
                try:
                    print(f"ê¸°ì‚¬ {i+1}/{len(article_urls)} í¬ë¡¤ë§ ì¤‘...")
                    page.goto(article_url)
                    time.sleep(2)
                    
                    # YTN ê¸°ì‚¬ ì œëª© ì¶”ì¶œ (ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„)
                    title_selectors = [
                        "h1",
                        ".article_title", 
                        ".news_title",
                        ".title",
                        ".headline",
                        "#article_title",
                        ".subject",
                        ".view_title"
                    ]
                    
                    title = ""
                    for selector in title_selectors:
                        try:
                            title_element = page.query_selector(selector)
                            if title_element:
                                title = title_element.inner_text().strip()
                                if len(title) > 5:  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ ì œëª©
                                    break
                        except:
                            continue
                    
                    if not title:
                        title = page.title() or "ì œëª© ì—†ìŒ"
                    
                    # ë³¸ë¬¸ ì¶”ì¶œ (YTN ë³¸ë¬¸ ì…€ë ‰í„°)
                    content_selectors = [
                        ".article_txt",
                        ".news_txt", 
                        ".view_txt",
                        "#article_text",
                        ".article-content",
                        ".content",
                        "article",
                        ".story_body"
                    ]
                    
                    content = ""
                    for selector in content_selectors:
                        try:
                            content_element = page.query_selector(selector)
                            if content_element:
                                content = content_element.inner_text().strip()
                                if len(content) > 100:  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ ë³¸ë¬¸
                                    break
                        except:
                            continue
                    
                    if not content:
                        content = "ë³¸ë¬¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    
                    # DBì— ì €ì¥
                    success = save_article_to_db(
                        supabase=supabase,
                        title=title,
                        content=content,
                        url=article_url,
                        media_outlet="YTN",
                        category=category['name']
                    )
                    
                    if success:
                        article_count += 1
                        print(f"âœ… {article_count}ë²ˆì§¸ ê¸°ì‚¬ ì €ì¥: {title[:50]}...")
                        
                        # 30ê°œ ìˆ˜ì§‘í•˜ë©´ ì¢…ë£Œ
                        if article_count >= 30:
                            break
                    
                except Exception as e:
                    print(f"âŒ ê¸°ì‚¬ í¬ë¡¤ë§ ì‹¤íŒ¨ {article_url}: {e}")
                    continue
            
            print(f"âœ… YTN {category['name']} ì™„ë£Œ: {article_count}ê°œ ìˆ˜ì§‘")
        
        browser.close()
        
        print(f"\n=== YTN ì´ 90ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ ===")
        # ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ëŠ” DBì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥
        print(" ì •ì¹˜: 30ê°œ")
        print(" ê²½ì œ: 30ê°œ") 
        print(" ì‚¬íšŒ: 30ê°œ")

if __name__ == "__main__":
    crawl_ytn()